{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/korkutanapa/ANOMALY_DETECTION_TDA_YAHOO_DATASET/blob/main/TDA_NAB_SOLUTIONS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSzWPE6xUzpf"
      },
      "source": [
        "# Version 11 optimization algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm6cl983j0sg",
        "outputId": "f2c17c2d-3a71-47ad-d874-d37059c0dc96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. CLEAN START ---\n",
            "Cloning into 'NAB'...\n",
            "remote: Enumerating objects: 7119, done.\u001b[K\n",
            "remote: Counting objects: 100% (699/699), done.\u001b[K\n",
            "remote: Compressing objects: 100% (204/204), done.\u001b[K\n",
            "remote: Total 7119 (delta 552), reused 495 (delta 495), pack-reused 6420 (from 1)\u001b[K\n",
            "Receiving objects: 100% (7119/7119), 86.13 MiB | 22.70 MiB/s, done.\n",
            "Resolving deltas: 100% (5001/5001), done.\n",
            "Updating files: 100% (1186/1186), done.\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=2, TOP_FINAL=3  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 2, 'TOP_FINAL': 3, 'standard': 33.85, 'lowFP': 31.14, 'lowFN': 36.07, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K2_TOP3.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=2, TOP_FINAL=5  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 2, 'TOP_FINAL': 5, 'standard': 38.11, 'lowFP': 33.02, 'lowFN': 41.5, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K2_TOP5.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=2, TOP_FINAL=7  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 2, 'TOP_FINAL': 7, 'standard': 40.52, 'lowFP': 32.7, 'lowFN': 45.12, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K2_TOP7.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=2, TOP_FINAL=9  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 2, 'TOP_FINAL': 9, 'standard': 40.87, 'lowFP': 29.31, 'lowFN': 46.79, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K2_TOP9.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=2, TOP_FINAL=11  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 2, 'TOP_FINAL': 11, 'standard': 42.67, 'lowFP': 27.99, 'lowFN': 49.71, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K2_TOP11.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=2, TOP_FINAL=13  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 2, 'TOP_FINAL': 13, 'standard': 41.79, 'lowFP': 24.32, 'lowFN': 49.7, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K2_TOP13.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=3, TOP_FINAL=3  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 3, 'TOP_FINAL': 3, 'standard': 32.39, 'lowFP': 29.62, 'lowFN': 34.52, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K3_TOP3.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=3, TOP_FINAL=5  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 3, 'TOP_FINAL': 5, 'standard': 39.17, 'lowFP': 34.03, 'lowFN': 42.49, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K3_TOP5.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=3, TOP_FINAL=7  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 3, 'TOP_FINAL': 7, 'standard': 41.32, 'lowFP': 33.74, 'lowFN': 45.65, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K3_TOP7.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=3, TOP_FINAL=9  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 3, 'TOP_FINAL': 9, 'standard': 45.83, 'lowFP': 35.87, 'lowFN': 51.24, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K3_TOP9.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=3, TOP_FINAL=11  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 3, 'TOP_FINAL': 11, 'standard': 44.22, 'lowFP': 31.16, 'lowFN': 50.75, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K3_TOP11.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=3, TOP_FINAL=13  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 3, 'TOP_FINAL': 13, 'standard': 45.95, 'lowFP': 29.45, 'lowFN': 53.62, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K3_TOP13.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=4, TOP_FINAL=3  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 4, 'TOP_FINAL': 3, 'standard': 33.18, 'lowFP': 30.59, 'lowFN': 35.34, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K4_TOP3.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=4, TOP_FINAL=5  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 4, 'TOP_FINAL': 5, 'standard': 40.04, 'lowFP': 35.05, 'lowFN': 43.36, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K4_TOP5.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=4, TOP_FINAL=7  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 4, 'TOP_FINAL': 7, 'standard': 42.82, 'lowFP': 35.16, 'lowFN': 47.23, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K4_TOP7.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=4, TOP_FINAL=9  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 4, 'TOP_FINAL': 9, 'standard': 43.03, 'lowFP': 32.73, 'lowFN': 48.51, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K4_TOP9.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=4, TOP_FINAL=11  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 4, 'TOP_FINAL': 11, 'standard': 45.79, 'lowFP': 33.12, 'lowFN': 52.08, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K4_TOP11.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=4, TOP_FINAL=13  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 4, 'TOP_FINAL': 13, 'standard': 45.14, 'lowFP': 29.53, 'lowFN': 52.51, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K4_TOP13.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=5, TOP_FINAL=3  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 5, 'TOP_FINAL': 3, 'standard': 34.87, 'lowFP': 32.18, 'lowFN': 37.04, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K5_TOP3.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=5, TOP_FINAL=5  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 5, 'TOP_FINAL': 5, 'standard': 39.39, 'lowFP': 34.24, 'lowFN': 42.64, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K5_TOP5.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=5, TOP_FINAL=7  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 5, 'TOP_FINAL': 7, 'standard': 40.94, 'lowFP': 32.86, 'lowFN': 45.39, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K5_TOP7.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=5, TOP_FINAL=9  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 5, 'TOP_FINAL': 9, 'standard': 43.23, 'lowFP': 32.26, 'lowFN': 48.94, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K5_TOP9.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=5, TOP_FINAL=11  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 5, 'TOP_FINAL': 11, 'standard': 43.87, 'lowFP': 30.46, 'lowFN': 50.51, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K5_TOP11.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=5, TOP_FINAL=13  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 5, 'TOP_FINAL': 13, 'standard': 48.09, 'lowFP': 32.37, 'lowFN': 55.62, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K5_TOP13.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=6, TOP_FINAL=3  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 6, 'TOP_FINAL': 3, 'standard': 35.75, 'lowFP': 33.14, 'lowFN': 37.92, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K6_TOP3.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=6, TOP_FINAL=5  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 6, 'TOP_FINAL': 5, 'standard': 39.34, 'lowFP': 34.1, 'lowFN': 42.61, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K6_TOP5.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=6, TOP_FINAL=7  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 6, 'TOP_FINAL': 7, 'standard': 41.03, 'lowFP': 32.98, 'lowFN': 45.46, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K6_TOP7.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=6, TOP_FINAL=9  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 6, 'TOP_FINAL': 9, 'standard': 43.84, 'lowFP': 32.76, 'lowFN': 49.63, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K6_TOP9.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=6, TOP_FINAL=11  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 6, 'TOP_FINAL': 11, 'standard': 48.57, 'lowFP': 34.99, 'lowFN': 55.37, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K6_TOP11.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=6, TOP_FINAL=13  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 6, 'TOP_FINAL': 13, 'standard': 50.56, 'lowFP': 34.53, 'lowFN': 58.42, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K6_TOP13.log', 'status': 'ok'}\n",
            "\n",
            "✅ Saved: /content/NAB/parameter_tuning_results.csv\n",
            "\n",
            "Top 10 by standard score:\n",
            "    K_PER_FEATURE  TOP_FINAL  standard  lowFP  lowFN status  \\\n",
            "29              6         13     50.56  34.53  58.42     ok   \n",
            "28              6         11     48.57  34.99  55.37     ok   \n",
            "23              5         13     48.09  32.37  55.62     ok   \n",
            "11              3         13     45.95  29.45  53.62     ok   \n",
            "9               3          9     45.83  35.87  51.24     ok   \n",
            "16              4         11     45.79  33.12  52.08     ok   \n",
            "17              4         13     45.14  29.53  52.51     ok   \n",
            "10              3         11     44.22  31.16  50.75     ok   \n",
            "22              5         11     43.87  30.46  50.51     ok   \n",
            "27              6          9     43.84  32.76  49.63     ok   \n",
            "\n",
            "                                       log_file  \n",
            "29  /content/NAB/tuning_logs/runpy_K6_TOP13.log  \n",
            "28  /content/NAB/tuning_logs/runpy_K6_TOP11.log  \n",
            "23  /content/NAB/tuning_logs/runpy_K5_TOP13.log  \n",
            "11  /content/NAB/tuning_logs/runpy_K3_TOP13.log  \n",
            "9    /content/NAB/tuning_logs/runpy_K3_TOP9.log  \n",
            "16  /content/NAB/tuning_logs/runpy_K4_TOP11.log  \n",
            "17  /content/NAB/tuning_logs/runpy_K4_TOP13.log  \n",
            "10  /content/NAB/tuning_logs/runpy_K3_TOP11.log  \n",
            "22  /content/NAB/tuning_logs/runpy_K5_TOP11.log  \n",
            "27   /content/NAB/tuning_logs/runpy_K6_TOP9.log  \n"
          ]
        }
      ],
      "source": [
        "import os, re, shutil, itertools, subprocess\n",
        "import pandas as pd\n",
        "\n",
        "# ============================================================\n",
        "# 1) CLEAN START & CLONE NAB\n",
        "# ============================================================\n",
        "print(\"--- 1. CLEAN START ---\")\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "if os.path.exists(\"NAB\"):\n",
        "    shutil.rmtree(\"NAB\")\n",
        "\n",
        "!git clone https://github.com/numenta/NAB.git\n",
        "!pip install -q ripser\n",
        "\n",
        "os.chdir(\"/content/NAB\")\n",
        "\n",
        "os.makedirs(\"config\", exist_ok=True)\n",
        "thr_path = os.path.join(\"config\", \"thresholds.json\")\n",
        "if not os.path.exists(thr_path):\n",
        "    with open(thr_path, \"w\") as f:\n",
        "        f.write(\"{}\")\n",
        "\n",
        "os.makedirs(\"tuning_logs\", exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# 2) TEMPLATE = YOUR my_algo.py CODE (UNCHANGED EXCEPT WE WILL\n",
        "#    regex-replace ONLY K_PER_FEATURE and TOP_FINAL)\n",
        "#    IMPORTANT: DETECTOR_NAME stays \"TDA_VEAD_Method\"\n",
        "# ============================================================\n",
        "TEMPLATE = r\"\"\"\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ripser import ripser\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "DETECTOR_NAME = \"TDA_VEAD_Method\"\n",
        "INPUT_DIR = \"data\"\n",
        "OUTPUT_DIR = os.path.join(\"results\", DETECTOR_NAME)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Embedding parameters (fixed in NAB for fairness)\n",
        "# ----------------------------------------------------------\n",
        "WINDOW_SIZE = 14\n",
        "TAU         = 1\n",
        "DIMENSION   = 7\n",
        "_EPS        = 1e-12\n",
        "MAXDIM      = 1  # H0 + H1\n",
        "\n",
        "# ==========================================================\n",
        "# 0. VEAD CONFIGURATION\n",
        "# ==========================================================\n",
        "KV   = 3.5\n",
        "KA   = 3.5\n",
        "MODE = \"abs_plateau\"  # \"strict\" | \"plateau\" | \"abs_plateau\"\n",
        "\n",
        "def _vead_series(raw_vals, kv=KV, ka=KA, mode=MODE):\n",
        "    s = pd.to_numeric(pd.Series(raw_vals, dtype=float), errors=\"coerce\") \\\n",
        "            .interpolate(limit_direction=\"both\")\n",
        "\n",
        "    v = s.diff(1)\n",
        "    a = v.diff(1)\n",
        "\n",
        "    def _zmad(x):\n",
        "        x = np.asarray(x, dtype=float)\n",
        "        med = np.nanmedian(x)\n",
        "        mad = np.nanmedian(np.abs(x - med)) + 1e-12\n",
        "        return (x - med) / mad\n",
        "\n",
        "    zv = _zmad(v.values)\n",
        "    za = _zmad(a.values)\n",
        "\n",
        "    mode = (mode or \"strict\").lower()\n",
        "    if mode == \"strict\":\n",
        "        zv = np.maximum(0.0, zv)\n",
        "        za = np.maximum(0.0, za)\n",
        "    elif mode == \"plateau\":\n",
        "        zv = np.where(zv > -0.25, zv, 0.0)\n",
        "        za = np.where(za > -0.25, za, 0.0)\n",
        "    elif mode == \"abs_plateau\":\n",
        "        zv = np.abs(zv)\n",
        "        za = np.abs(za)\n",
        "\n",
        "    score = (kv * zv) * (ka * za)\n",
        "    return np.nan_to_num(score, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "# ==========================================================\n",
        "# 1. TAKENS EMBEDDING\n",
        "# ==========================================================\n",
        "def takens_embed(window, time_delay, dimension):\n",
        "    m = len(window) - (dimension - 1) * time_delay\n",
        "    if m <= 0:\n",
        "        raise ValueError(\"Takens parameters too large for this window.\")\n",
        "    return np.stack(\n",
        "        [window[j:j + m * time_delay:time_delay] for j in range(dimension)],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "# ==========================================================\n",
        "# 2. PERSISTENCE DIAGRAM UTILITIES + FEATURE FUNCTIONS\n",
        "# ==========================================================\n",
        "def _clean_diag(diag):\n",
        "    if diag is None:\n",
        "        return np.empty((0, 2), dtype=float)\n",
        "    arr = np.asarray(diag, dtype=float)\n",
        "    if arr.ndim != 2 or arr.shape[1] != 2 or arr.size == 0:\n",
        "        return np.empty((0, 2), dtype=float)\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    mask = np.isfinite(b) & np.isfinite(d) & (d > b)\n",
        "    if not np.any(mask):\n",
        "        return np.empty((0, 2), dtype=float)\n",
        "    return np.stack([b[mask], d[mask]], axis=1)\n",
        "\n",
        "def _lifetimes(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return np.empty(0, dtype=float)\n",
        "    return np.maximum(arr[:, 1] - arr[:, 0], 0.0)\n",
        "\n",
        "def _safe_div(a, b):\n",
        "    return float(a) / float(b + _EPS)\n",
        "\n",
        "try:\n",
        "    _trapz = np.trapezoid\n",
        "except AttributeError:\n",
        "    _trapz = np.trapz\n",
        "\n",
        "def _auc_tri_max(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return 0.0\n",
        "    b_all, d_all = arr[:, 0], arr[:, 1]\n",
        "    if b_all.min() == d_all.max():\n",
        "        return 0.0\n",
        "\n",
        "    grid = np.linspace(b_all.min(), d_all.max(), 64)\n",
        "    lam1 = np.zeros_like(grid)\n",
        "\n",
        "    for b, d in arr:\n",
        "        m = 0.5 * (b + d)\n",
        "        h = 0.5 * (d - b)\n",
        "        if h <= 0:\n",
        "            continue\n",
        "\n",
        "        left = (grid >= b) & (grid <= m)\n",
        "        right = (grid >= m) & (grid <= d)\n",
        "\n",
        "        lam1[left] = np.maximum(lam1[left], (grid[left] - b) * (h / max(m - b, _EPS)))\n",
        "        lam1[right] = np.maximum(lam1[right], (d - grid[right]) * (h / max(d - m, _EPS)))\n",
        "\n",
        "    return float(_trapz(lam1, grid))\n",
        "\n",
        "def _persistence_entropy(diag):\n",
        "    L = _lifetimes(diag)\n",
        "    if L.size == 0:\n",
        "        return 0.0\n",
        "    S = L.sum()\n",
        "    if S <= 0:\n",
        "        return 0.0\n",
        "    p = L / (S + _EPS)\n",
        "    return float(-np.sum(p * np.log(p + _EPS)))\n",
        "\n",
        "def _gini_from_lifetimes(L):\n",
        "    L = np.sort(L)\n",
        "    n = len(L)\n",
        "    if n == 0:\n",
        "        return 0.0\n",
        "    S = L.sum()\n",
        "    if S <= 0:\n",
        "        return 0.0\n",
        "    cumL = np.cumsum(L)\n",
        "    return float(1 + 1/n - 2*np.sum(cumL/(n*S)))\n",
        "\n",
        "def _tail_share_q(diag, q):\n",
        "    L = _lifetimes(diag)\n",
        "    if L.size == 0:\n",
        "        return 0.0\n",
        "    qv = np.quantile(L, q)\n",
        "    return _safe_div(L[L >= qv].sum(), L.sum())\n",
        "\n",
        "def _birth_death_stats(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return {\"mean_birth\": 0.0, \"mean_death\": 0.0, \"std_birth\": 0.0, \"std_death\": 0.0}\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    return {\n",
        "        \"mean_birth\": float(b.mean()),\n",
        "        \"mean_death\": float(d.mean()),\n",
        "        \"std_birth\": float(b.std(ddof=0)),\n",
        "        \"std_death\": float(d.std(ddof=0)),\n",
        "    }\n",
        "\n",
        "def _diag_distance_stats(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return {\"mean_diag_dist\": 0.0, \"max_diag_dist\": 0.0, \"sum_diag_dist\": 0.0}\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    dist = (d - b) / np.sqrt(2.0)\n",
        "    return {\n",
        "        \"mean_diag_dist\": float(dist.mean()),\n",
        "        \"max_diag_dist\": float(dist.max()),\n",
        "        \"sum_diag_dist\": float(dist.sum()),\n",
        "    }\n",
        "\n",
        "def _centroid_xy(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return {\"centroid_x\": 0.0, \"centroid_y\": 0.0}\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    L = np.maximum(d - b, 0.0)\n",
        "    S = L.sum()\n",
        "    if S <= 0:\n",
        "        return {\"centroid_x\": 0.0, \"centroid_y\": 0.0}\n",
        "    return {\n",
        "        \"centroid_x\": float(np.sum(b * L) / (S + _EPS)),\n",
        "        \"centroid_y\": float(np.sum(d * L) / (S + _EPS)),\n",
        "    }\n",
        "\n",
        "def _lifetimes_stats(diag):\n",
        "    L = _lifetimes(diag)\n",
        "    if L.size == 0:\n",
        "        return {\n",
        "            \"count\": 0, \"sum\": 0.0, \"mean\": 0.0, \"median\": 0.0, \"std\": 0.0,\n",
        "            \"min\": 0.0, \"max\": 0.0, \"L1\": 0.0, \"L2\": 0.0, \"Linf\": 0.0\n",
        "        }\n",
        "    return {\n",
        "        \"count\": int(L.size),\n",
        "        \"sum\": float(L.sum()),\n",
        "        \"mean\": float(L.mean()),\n",
        "        \"median\": float(np.median(L)),\n",
        "        \"std\": float(L.std(ddof=0)),\n",
        "        \"min\": float(L.min()),\n",
        "        \"max\": float(L.max()),\n",
        "        \"L1\": float(np.sum(np.abs(L))),\n",
        "        \"L2\": float(np.sqrt(np.sum(L**2))),\n",
        "        \"Linf\": float(np.max(np.abs(L))),\n",
        "    }\n",
        "\n",
        "def _lifetimes_quantiles(diag):\n",
        "    L = _lifetimes(diag)\n",
        "    if L.size == 0:\n",
        "        return {\"q50\": 0.0, \"q75\": 0.0, \"q90\": 0.0, \"q95\": 0.0, \"q99\": 0.0}\n",
        "    return {\n",
        "        \"q50\": float(np.quantile(L, 0.50)),\n",
        "        \"q75\": float(np.quantile(L, 0.75)),\n",
        "        \"q90\": float(np.quantile(L, 0.90)),\n",
        "        \"q95\": float(np.quantile(L, 0.95)),\n",
        "        \"q99\": float(np.quantile(L, 0.99)),\n",
        "    }\n",
        "\n",
        "def _carlsson_coordinates(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return {f\"f{k}\": 0.0 for k in range(1, 6)}\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    L = np.maximum(d - b, 0.0)\n",
        "    S = L.sum()\n",
        "    if S <= 0:\n",
        "        return {f\"f{k}\": 0.0 for k in range(1, 6)}\n",
        "    return {\n",
        "        \"f1\": float(L.sum()),\n",
        "        \"f2\": float(np.sum(b * L)),\n",
        "        \"f3\": float(np.sum(d * L)),\n",
        "        \"f4\": float(np.sum(b**2 * L)),\n",
        "        \"f5\": float(np.sum(d**2 * L)),\n",
        "    }\n",
        "\n",
        "def _sum_centroid_radial(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return 0.0\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    L = np.maximum(d - b, 0.0)\n",
        "    S = L.sum()\n",
        "    if S <= 0:\n",
        "        return 0.0\n",
        "    radial = (b + d) / np.sqrt(2.0)\n",
        "    return _safe_div(np.sum(np.abs(radial) * L), S)\n",
        "\n",
        "def _pete(diag, p=1.6, q=0.5):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return 0.0\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    L = np.maximum(d - b, 0.0)\n",
        "    S = L.sum()\n",
        "    if S <= 0:\n",
        "        return 0.0\n",
        "    radial = (b + d) / np.sqrt(2.0)\n",
        "    return _safe_div(np.sum((L**p) * (np.abs(radial)**q)), S)\n",
        "\n",
        "def compute_features_for_diag(diag, prefix):\n",
        "    feats = {}\n",
        "\n",
        "    Ls = _lifetimes_stats(diag)\n",
        "    feats[f\"{prefix}count_lifetime\"] = float(Ls[\"count\"])\n",
        "    feats[f\"{prefix}sum_lifetime\"]   = float(Ls[\"sum\"])\n",
        "    feats[f\"{prefix}mean_lifetime\"]  = float(Ls[\"mean\"])\n",
        "    feats[f\"{prefix}median_lifetime\"]= float(Ls[\"median\"])\n",
        "    feats[f\"{prefix}std_lifetime\"]   = float(Ls[\"std\"])\n",
        "    feats[f\"{prefix}min_lifetime\"]   = float(Ls[\"min\"])\n",
        "    feats[f\"{prefix}max_lifetime\"]   = float(Ls[\"max\"])\n",
        "\n",
        "    feats[f\"{prefix}L1_lifetime\"]    = float(Ls[\"L1\"])\n",
        "    feats[f\"{prefix}L2_lifetime\"]    = float(Ls[\"L2\"])\n",
        "    feats[f\"{prefix}Linf_lifetime\"]  = float(Ls[\"Linf\"])\n",
        "\n",
        "    feats[f\"{prefix}L1_norm\"]        = float(Ls[\"L1\"])\n",
        "    feats[f\"{prefix}L2_norm\"]        = float(Ls[\"L2\"])\n",
        "    feats[f\"{prefix}Linf_norm\"]      = float(Ls[\"Linf\"])\n",
        "\n",
        "    feats[f\"{prefix}betti\"]          = float(Ls[\"count\"])\n",
        "    feats[f\"{prefix}energy_concentration\"] = _safe_div(Ls[\"L2\"], Ls[\"L1\"])\n",
        "    feats[f\"{prefix}dominance_share\"]      = _safe_div(Ls[\"Linf\"], Ls[\"L1\"])\n",
        "\n",
        "    feats[f\"{prefix}persistence_entropy\"]  = _persistence_entropy(diag)\n",
        "\n",
        "    bd = _birth_death_stats(diag)\n",
        "    for k, v in bd.items():\n",
        "        feats[f\"{prefix}{k}\"] = float(v)\n",
        "\n",
        "    dd = _diag_distance_stats(diag)\n",
        "    for k, v in dd.items():\n",
        "        feats[f\"{prefix}{k}\"] = float(v)\n",
        "\n",
        "    cxy = _centroid_xy(diag)\n",
        "    feats[f\"{prefix}centroid_x\"] = float(cxy[\"centroid_x\"])\n",
        "    feats[f\"{prefix}centroid_y\"] = float(cxy[\"centroid_y\"])\n",
        "\n",
        "    q = _lifetimes_quantiles(diag)\n",
        "    for k, v in q.items():\n",
        "        feats[f\"{prefix}{k}\"] = float(v)\n",
        "\n",
        "    tail80 = _tail_share_q(diag, 0.80)\n",
        "    tail90 = _tail_share_q(diag, 0.90)\n",
        "    tail95 = _tail_share_q(diag, 0.95)\n",
        "\n",
        "    feats[f\"{prefix}tail_share_q80\"] = float(tail80)\n",
        "    feats[f\"{prefix}tail_share_q90\"] = float(tail90)\n",
        "    feats[f\"{prefix}tail_share_q95\"] = float(tail95)\n",
        "    feats[f\"{prefix}tail_curvature_80_90\"] = float(tail90 - tail80)\n",
        "\n",
        "    L = _lifetimes(diag)\n",
        "    feats[f\"{prefix}gini\"] = float(_gini_from_lifetimes(L))\n",
        "\n",
        "    cc = _carlsson_coordinates(diag)\n",
        "    feats[f\"{prefix}Carlsson_f1\"] = float(cc[\"f1\"])\n",
        "    feats[f\"{prefix}Carlsson_f2\"] = float(cc[\"f2\"])\n",
        "    feats[f\"{prefix}Carlsson_f3\"] = float(cc[\"f3\"])\n",
        "    feats[f\"{prefix}Carlsson_f4\"] = float(cc[\"f4\"])\n",
        "    feats[f\"{prefix}Carlsson_f5\"] = float(cc[\"f5\"])\n",
        "\n",
        "    if prefix == \"H0_\":\n",
        "        A = _auc_tri_max(diag)\n",
        "        feats[\"H0_ratio_auc_L1_to_sum\"] = _safe_div(A, Ls[\"sum\"])\n",
        "        feats[\"H0_ratio_auc_to_max\"]    = _safe_div(A, Ls[\"max\"])\n",
        "        feats[\"H0_ratio_auc_to_l2\"]     = _safe_div(A, Ls[\"L2\"])\n",
        "        feats[\"H0_bottleneck\"]          = float(Ls[\"max\"])\n",
        "        feats[\"H0_sum_centroid\"]        = float(_sum_centroid_radial(diag))\n",
        "        feats[\"PETE_p1.6_q0.5\"]         = float(_pete(diag, p=1.6, q=0.5))\n",
        "        feats[\"H0_energy_concentration\"]= _safe_div(Ls[\"L2\"], Ls[\"sum\"])\n",
        "        feats[\"H0_dominance_share\"]     = _safe_div(Ls[\"Linf\"], Ls[\"sum\"])\n",
        "        feats[\"H0_tail_curvature_80_90\"]= float(tail90 - tail80)\n",
        "        feats[\"H0_centroid_to_energy\"]  = _safe_div(feats[\"H0_sum_centroid\"], Ls[\"L2\"])\n",
        "        feats[\"H0_gini\"]                = float(feats[\"H0_gini\"])\n",
        "    return feats\n",
        "\n",
        "def compute_cross_dim_features(feats_H0, feats_H1):\n",
        "    out = {}\n",
        "    def g(d, k): return float(d.get(k, 0.0))\n",
        "    out[\"H1_to_H0_betti_ratio\"]   = _safe_div(g(feats_H1, \"H1_betti\"), g(feats_H0, \"H0_betti\"))\n",
        "    out[\"H1_to_H0_entropy_ratio\"] = _safe_div(g(feats_H1, \"H1_persistence_entropy\"), g(feats_H0, \"H0_persistence_entropy\"))\n",
        "    return out\n",
        "\n",
        "FEATURE_NAMES = [\n",
        "    \"H0_Carlsson_f1\",\"H0_Carlsson_f3\",\"H0_Carlsson_f5\",\n",
        "    \"H0_L1_lifetime\",\"H0_L1_norm\",\"H0_L2_lifetime\",\"H0_L2_norm\",\n",
        "    \"H0_Linf_lifetime\",\"H0_Linf_norm\",\"H0_bottleneck\",\"H0_centroid_to_energy\",\n",
        "    \"H0_centroid_y\",\"H0_dominance_share\",\"H0_energy_concentration\",\"H0_gini\",\n",
        "    \"H0_max_diag_dist\",\"H0_max_lifetime\",\"H0_mean_death\",\"H0_mean_diag_dist\",\n",
        "    \"H0_mean_lifetime\",\"H0_median_lifetime\",\"H0_min_lifetime\",\"H0_persistence_entropy\",\n",
        "    \"H0_q50\",\"H0_q75\",\"H0_q90\",\"H0_q95\",\"H0_q99\",\"H0_ratio_auc_L1_to_sum\",\n",
        "    \"H0_ratio_auc_to_l2\",\"H0_ratio_auc_to_max\",\"H0_std_death\",\"H0_std_lifetime\",\n",
        "    \"H0_sum_centroid\",\"H0_sum_diag_dist\",\"H0_sum_lifetime\",\"H0_tail_curvature_80_90\",\n",
        "    \"H0_tail_share_q80\",\"H0_tail_share_q90\",\"H0_tail_share_q95\",\n",
        "    \"H1_Carlsson_f1\",\"H1_Carlsson_f2\",\"H1_Carlsson_f3\",\n",
        "    \"H1_L1_lifetime\",\"H1_L1_norm\",\"H1_L2_lifetime\",\"H1_L2_norm\",\n",
        "    \"H1_Linf_lifetime\",\"H1_Linf_norm\",\"H1_betti\",\"H1_count_lifetime\",\n",
        "    \"H1_dominance_share\",\"H1_energy_concentration\",\"H1_gini\",\n",
        "    \"H1_max_diag_dist\",\"H1_max_lifetime\",\"H1_mean_diag_dist\",\"H1_mean_lifetime\",\n",
        "    \"H1_median_lifetime\",\"H1_min_lifetime\",\"H1_persistence_entropy\",\n",
        "    \"H1_q50\",\"H1_q75\",\"H1_q90\",\"H1_q95\",\"H1_q99\",\n",
        "    \"H1_std_birth\",\"H1_std_death\",\"H1_std_lifetime\",\n",
        "    \"H1_sum_diag_dist\",\"H1_sum_lifetime\",\n",
        "    \"H1_tail_share_q80\",\"H1_tail_share_q90\",\"H1_tail_share_q95\",\n",
        "    \"H1_to_H0_betti_ratio\",\"H1_to_H0_entropy_ratio\",\n",
        "    \"PETE_p1.6_q0.5\"\n",
        "]\n",
        "\n",
        "def run():\n",
        "    files = glob.glob(os.path.join(INPUT_DIR, \"**\", \"*.csv\"), recursive=True)\n",
        "    print(f\"Found {len(files)} data files in '{INPUT_DIR}'\")\n",
        "\n",
        "    ##############################################################################################################\n",
        "    # Voting config\n",
        "    K_PER_FEATURE = 4  # each feature votes for top-2 indices\n",
        "    TOP_FINAL     = 10  # final anomalies = top-5 voted indices\n",
        "    ########################################################################################################################333\n",
        "\n",
        "    for filepath in files:\n",
        "        if \".ipynb_checkpoints\" in filepath:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(filepath)\n",
        "            df.columns = [c.strip().lower() for c in df.columns]\n",
        "            if \"value\" not in df.columns or \"timestamp\" not in df.columns:\n",
        "                continue\n",
        "\n",
        "            vals = pd.to_numeric(df[\"value\"], errors=\"coerce\").astype(float).to_numpy()\n",
        "            n = len(vals)\n",
        "\n",
        "            rows = []\n",
        "            for i in range(WINDOW_SIZE - 1, n):\n",
        "                w = vals[i - WINDOW_SIZE + 1 : i + 1]\n",
        "                try:\n",
        "                    emb = takens_embed(w, TAU, DIMENSION)\n",
        "                    dgms = ripser(emb, maxdim=MAXDIM)[\"dgms\"]\n",
        "                except Exception:\n",
        "                    dgms = [np.empty((0, 2)), np.empty((0, 2))]\n",
        "\n",
        "                D0 = dgms[0] if len(dgms) > 0 else np.empty((0, 2))\n",
        "                D1 = dgms[1] if (MAXDIM >= 1 and len(dgms) > 1) else np.empty((0, 2))\n",
        "\n",
        "                feats_H0 = compute_features_for_diag(D0, \"H0_\")\n",
        "                feats_H1 = compute_features_for_diag(D1, \"H1_\")\n",
        "                cross    = compute_cross_dim_features(feats_H0, feats_H1)\n",
        "\n",
        "                merged = {}\n",
        "                merged.update(feats_H0)\n",
        "                merged.update(feats_H1)\n",
        "                merged.update(cross)\n",
        "                merged[\"index\"] = i\n",
        "                rows.append(merged)\n",
        "\n",
        "            feat_df = pd.DataFrame(rows)\n",
        "            full = pd.DataFrame(index=np.arange(n))\n",
        "            if not feat_df.empty:\n",
        "                feat_df = feat_df.set_index(\"index\")\n",
        "                full = full.join(feat_df, how=\"left\")\n",
        "\n",
        "            full = full.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "\n",
        "            votes = np.zeros(n, dtype=int)\n",
        "\n",
        "            for feat_name in FEATURE_NAMES:\n",
        "                series = pd.to_numeric(full.get(feat_name, 0.0), errors=\"coerce\").astype(float).to_numpy()\n",
        "                series = np.nan_to_num(series, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "                vead_scores = _vead_series(series, kv=KV, ka=KA, mode=MODE)\n",
        "\n",
        "                mx = float(np.max(vead_scores)) if len(vead_scores) else 0.0\n",
        "                if (not np.isfinite(mx)) or mx <= 0:\n",
        "                    continue\n",
        "\n",
        "                scores01 = np.clip(vead_scores / mx, 0.0, 1.0)\n",
        "                if np.max(scores01) <= 0:\n",
        "                    continue\n",
        "\n",
        "                k_eff = min(K_PER_FEATURE, n)\n",
        "                topk_idx = np.argpartition(scores01, -k_eff)[-k_eff:]\n",
        "                topk_idx = topk_idx[np.lexsort((topk_idx, -scores01[topk_idx]))]\n",
        "                votes[topk_idx] += 1\n",
        "\n",
        "            final_scores = np.zeros(n, dtype=float)\n",
        "            if np.max(votes) > 0:\n",
        "                top_final_eff = min(TOP_FINAL, n)\n",
        "                order = np.lexsort((np.arange(n), -votes))\n",
        "                chosen = order[:top_final_eff]\n",
        "                final_scores[chosen] = 1.0\n",
        "\n",
        "            rel = os.path.relpath(filepath, INPUT_DIR)\n",
        "            category = os.path.dirname(rel)\n",
        "            base_name = os.path.basename(rel)\n",
        "\n",
        "            out_dir = os.path.join(OUTPUT_DIR, category)\n",
        "            os.makedirs(out_dir, exist_ok=True)\n",
        "            out_name = f\"{DETECTOR_NAME}_\" + base_name\n",
        "            out_path = os.path.join(out_dir, out_name)\n",
        "\n",
        "            out_df = pd.DataFrame({\n",
        "                \"timestamp\": df[\"timestamp\"],\n",
        "                \"anomaly_score\": final_scores\n",
        "            })\n",
        "            out_df.to_csv(out_path, index=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"!! Error processing {filepath}: {e}\")\n",
        "            continue\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run()\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================\n",
        "# 3) Helpers\n",
        "# ============================================================\n",
        "def run_cmd(cmd_list):\n",
        "    p = subprocess.run(cmd_list, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    return p.returncode, p.stdout\n",
        "\n",
        "def parse_final_scores(text):\n",
        "    # works for ANY profile names printed by NAB\n",
        "    pat = r\"Final score for '([^']+)' detector on '([^']+)' profile = ([\\-0-9.]+)\"\n",
        "    found = re.findall(pat, text)\n",
        "    # returns dict: {(detectorLabel, profileName): score}\n",
        "    return {(d, prof): float(val) for d, prof, val in found}\n",
        "\n",
        "def make_variant_code(template, K, TOP):\n",
        "    code = template\n",
        "    code = re.sub(r'K_PER_FEATURE\\s*=\\s*\\d+', f'K_PER_FEATURE = {K}', code, count=1)\n",
        "    code = re.sub(r'TOP_FINAL\\s*=\\s*\\d+',     f'TOP_FINAL = {TOP}', code, count=1)\n",
        "    return code\n",
        "\n",
        "# ============================================================\n",
        "# 4) GRID SEARCH\n",
        "# ============================================================\n",
        "K_LIST   = [2, 3, 4, 5, 6]\n",
        "TOP_LIST = [3, 5, 7, 9, 11, 13]\n",
        "\n",
        "results = []\n",
        "\n",
        "for K, TOP in itertools.product(K_LIST, TOP_LIST):\n",
        "    exp_id = f\"K{K}_TOP{TOP}\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"EXPERIMENT: K_PER_FEATURE={K}, TOP_FINAL={TOP}  ->  TDA_VEAD_Method\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Write detector code (only K/TOP changed)\n",
        "    code = make_variant_code(TEMPLATE, K, TOP)\n",
        "    with open(\"my_algo.py\", \"w\") as f:\n",
        "        f.write(code)\n",
        "\n",
        "    # Run detector (generates results/TDA_VEAD_Method/*)\n",
        "    rc1, out1 = run_cmd([\"python\", \"my_algo.py\"])\n",
        "    if rc1 != 0:\n",
        "        print(\"Detector failed.\")\n",
        "        results.append({\n",
        "            \"K_PER_FEATURE\": K, \"TOP_FINAL\": TOP,\n",
        "            \"standard\": None, \"lowFP\": None, \"lowFN\": None,\n",
        "            \"status\": \"detector_failed\"\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # Run NAB scoring (IMPORTANT: --skipConfirmation)\n",
        "    rc2, out2 = run_cmd([\n",
        "        \"python\", \"run.py\",\n",
        "        \"--optimize\", \"--score\",\n",
        "        \"--detectors\", \"TDA_VEAD_Method\",\n",
        "        \"--normalize\",\n",
        "        \"--skipConfirmation\"\n",
        "    ])\n",
        "\n",
        "    # Save full log for this experiment (super useful)\n",
        "    log_path = f\"/content/NAB/tuning_logs/runpy_{exp_id}.log\"\n",
        "    with open(log_path, \"w\") as f:\n",
        "        f.write(out2)\n",
        "\n",
        "    scores = parse_final_scores(out2)\n",
        "\n",
        "    # Try to pick the usual 3 profiles if they exist; otherwise leave None\n",
        "    # Note: detector label in NAB output is often 'TDA' even if detector module is custom.\n",
        "    # So we search across any detector label.\n",
        "    def pick(profile_name):\n",
        "        for (det_label, prof), val in scores.items():\n",
        "            if prof == profile_name:\n",
        "                return val\n",
        "        return None\n",
        "\n",
        "    row = {\n",
        "        \"K_PER_FEATURE\": K,\n",
        "        \"TOP_FINAL\": TOP,\n",
        "        \"standard\": pick(\"standard\") or pick(\"VEAD_Method_standard\"),\n",
        "        \"lowFP\":    pick(\"reward_low_FP_rate\") or pick(\"VEAD_Method_reward_low_FP_rate\"),\n",
        "        \"lowFN\":    pick(\"reward_low_FN_rate\") or pick(\"VEAD_Method_reward_low_FN_rate\"),\n",
        "        \"rc_score\": rc2,\n",
        "        \"log_file\": log_path,\n",
        "        \"status\": \"ok\" if (rc2 == 0 and len(scores) > 0) else \"score_parse_failed\"\n",
        "    }\n",
        "    results.append(row)\n",
        "    print(\"Extracted:\", row)\n",
        "\n",
        "# ============================================================\n",
        "# 5) SAVE RESULTS\n",
        "# ============================================================\n",
        "res_df = pd.DataFrame(results)\n",
        "out_csv = \"/content/NAB/parameter_tuning_results.csv\"\n",
        "res_df.to_csv(out_csv, index=False)\n",
        "print(\"\\n✅ Saved:\", out_csv)\n",
        "\n",
        "best = res_df.dropna(subset=[\"standard\"]).sort_values(\"standard\", ascending=False).head(10)\n",
        "print(\"\\nTop 10 by standard score:\")\n",
        "print(best[[\"K_PER_FEATURE\",\"TOP_FINAL\",\"standard\",\"lowFP\",\"lowFN\",\"status\",\"log_file\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UacXTql74624"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4168e0c-e0f9-4f20-8fc7-b934d4700aca",
        "id": "USbyVF1847gF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. CLEAN START ---\n",
            "Cloning into 'NAB'...\n",
            "remote: Enumerating objects: 7119, done.\u001b[K\n",
            "remote: Counting objects: 100% (713/713), done.\u001b[K\n",
            "remote: Compressing objects: 100% (168/168), done.\u001b[K\n",
            "remote: Total 7119 (delta 601), reused 545 (delta 545), pack-reused 6406 (from 1)\u001b[K\n",
            "Receiving objects: 100% (7119/7119), 86.73 MiB | 21.82 MiB/s, done.\n",
            "Resolving deltas: 100% (5015/5015), done.\n",
            "Updating files: 100% (1186/1186), done.\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=6, TOP_FINAL=11  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 6, 'TOP_FINAL': 11, 'standard': 48.57, 'lowFP': 34.99, 'lowFN': 55.37, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K6_TOP11.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=6, TOP_FINAL=13  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 6, 'TOP_FINAL': 13, 'standard': 50.56, 'lowFP': 34.53, 'lowFN': 58.42, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K6_TOP13.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=6, TOP_FINAL=15  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 6, 'TOP_FINAL': 15, 'standard': 50.76, 'lowFP': 32.31, 'lowFN': 59.42, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K6_TOP15.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=6, TOP_FINAL=17  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 6, 'TOP_FINAL': 17, 'standard': 48.91, 'lowFP': 27.68, 'lowFN': 58.47, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K6_TOP17.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=6, TOP_FINAL=19  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 6, 'TOP_FINAL': 19, 'standard': 47.74, 'lowFP': 23.47, 'lowFN': 58.26, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K6_TOP19.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=7, TOP_FINAL=11  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 7, 'TOP_FINAL': 11, 'standard': 43.35, 'lowFP': 29.43, 'lowFN': 50.16, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K7_TOP11.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=7, TOP_FINAL=13  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 7, 'TOP_FINAL': 13, 'standard': 47.26, 'lowFP': 31.12, 'lowFN': 55.07, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K7_TOP13.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=7, TOP_FINAL=15  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 7, 'TOP_FINAL': 15, 'standard': 49.22, 'lowFP': 30.68, 'lowFN': 57.81, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K7_TOP15.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=7, TOP_FINAL=17  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 7, 'TOP_FINAL': 17, 'standard': 47.64, 'lowFP': 26.61, 'lowFN': 57.04, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K7_TOP17.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=7, TOP_FINAL=19  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 7, 'TOP_FINAL': 19, 'standard': 47.64, 'lowFP': 23.73, 'lowFN': 57.91, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K7_TOP19.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=8, TOP_FINAL=11  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 8, 'TOP_FINAL': 11, 'standard': 43.98, 'lowFP': 30.12, 'lowFN': 50.58, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K8_TOP11.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=8, TOP_FINAL=13  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 8, 'TOP_FINAL': 13, 'standard': 47.16, 'lowFP': 30.88, 'lowFN': 54.72, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K8_TOP13.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=8, TOP_FINAL=15  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 8, 'TOP_FINAL': 15, 'standard': 47.56, 'lowFP': 28.59, 'lowFN': 56.13, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K8_TOP15.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=8, TOP_FINAL=17  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 8, 'TOP_FINAL': 17, 'standard': 49.69, 'lowFP': 28.32, 'lowFN': 59.28, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K8_TOP17.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=8, TOP_FINAL=19  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 8, 'TOP_FINAL': 19, 'standard': 47.59, 'lowFP': 23.26, 'lowFN': 58.16, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K8_TOP19.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=9, TOP_FINAL=11  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 9, 'TOP_FINAL': 11, 'standard': 41.46, 'lowFP': 27.82, 'lowFN': 47.75, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K9_TOP11.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=9, TOP_FINAL=13  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 9, 'TOP_FINAL': 13, 'standard': 47.25, 'lowFP': 30.79, 'lowFN': 54.78, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K9_TOP13.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=9, TOP_FINAL=15  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 9, 'TOP_FINAL': 15, 'standard': 48.81, 'lowFP': 29.73, 'lowFN': 57.25, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K9_TOP15.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=9, TOP_FINAL=17  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 9, 'TOP_FINAL': 17, 'standard': 48.33, 'lowFP': 26.47, 'lowFN': 58.08, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K9_TOP17.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=9, TOP_FINAL=19  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 9, 'TOP_FINAL': 19, 'standard': 47.51, 'lowFP': 23.04, 'lowFN': 58.11, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K9_TOP19.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=10, TOP_FINAL=11  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 10, 'TOP_FINAL': 11, 'standard': 42.96, 'lowFP': 29.28, 'lowFN': 49.33, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K10_TOP11.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=10, TOP_FINAL=13  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 10, 'TOP_FINAL': 13, 'standard': 44.52, 'lowFP': 28.17, 'lowFN': 52.09, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K10_TOP13.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=10, TOP_FINAL=15  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 10, 'TOP_FINAL': 15, 'standard': 48.33, 'lowFP': 29.15, 'lowFN': 56.93, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K10_TOP15.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=10, TOP_FINAL=17  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 10, 'TOP_FINAL': 17, 'standard': 49.09, 'lowFP': 26.84, 'lowFN': 58.88, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K10_TOP17.log', 'status': 'ok'}\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: K_PER_FEATURE=10, TOP_FINAL=19  ->  TDA_VEAD_Method\n",
            "================================================================================\n",
            "Extracted: {'K_PER_FEATURE': 10, 'TOP_FINAL': 19, 'standard': 48.0, 'lowFP': 22.72, 'lowFN': 59.01, 'rc_score': 0, 'log_file': '/content/NAB/tuning_logs/runpy_K10_TOP19.log', 'status': 'ok'}\n",
            "\n",
            "✅ Saved: /content/NAB/parameter_tuning_results.csv\n",
            "\n",
            "Top 10 by standard score:\n",
            "    K_PER_FEATURE  TOP_FINAL  standard  lowFP  lowFN status  \\\n",
            "2               6         15     50.76  32.31  59.42     ok   \n",
            "1               6         13     50.56  34.53  58.42     ok   \n",
            "13              8         17     49.69  28.32  59.28     ok   \n",
            "7               7         15     49.22  30.68  57.81     ok   \n",
            "23             10         17     49.09  26.84  58.88     ok   \n",
            "3               6         17     48.91  27.68  58.47     ok   \n",
            "17              9         15     48.81  29.73  57.25     ok   \n",
            "0               6         11     48.57  34.99  55.37     ok   \n",
            "22             10         15     48.33  29.15  56.93     ok   \n",
            "18              9         17     48.33  26.47  58.08     ok   \n",
            "\n",
            "                                        log_file  \n",
            "2    /content/NAB/tuning_logs/runpy_K6_TOP15.log  \n",
            "1    /content/NAB/tuning_logs/runpy_K6_TOP13.log  \n",
            "13   /content/NAB/tuning_logs/runpy_K8_TOP17.log  \n",
            "7    /content/NAB/tuning_logs/runpy_K7_TOP15.log  \n",
            "23  /content/NAB/tuning_logs/runpy_K10_TOP17.log  \n",
            "3    /content/NAB/tuning_logs/runpy_K6_TOP17.log  \n",
            "17   /content/NAB/tuning_logs/runpy_K9_TOP15.log  \n",
            "0    /content/NAB/tuning_logs/runpy_K6_TOP11.log  \n",
            "22  /content/NAB/tuning_logs/runpy_K10_TOP15.log  \n",
            "18   /content/NAB/tuning_logs/runpy_K9_TOP17.log  \n"
          ]
        }
      ],
      "source": [
        "import os, re, shutil, itertools, subprocess\n",
        "import pandas as pd\n",
        "\n",
        "# ============================================================\n",
        "# 1) CLEAN START & CLONE NAB\n",
        "# ============================================================\n",
        "print(\"--- 1. CLEAN START ---\")\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "if os.path.exists(\"NAB\"):\n",
        "    shutil.rmtree(\"NAB\")\n",
        "\n",
        "!git clone https://github.com/numenta/NAB.git\n",
        "!pip install -q ripser\n",
        "\n",
        "os.chdir(\"/content/NAB\")\n",
        "\n",
        "os.makedirs(\"config\", exist_ok=True)\n",
        "thr_path = os.path.join(\"config\", \"thresholds.json\")\n",
        "if not os.path.exists(thr_path):\n",
        "    with open(thr_path, \"w\") as f:\n",
        "        f.write(\"{}\")\n",
        "\n",
        "os.makedirs(\"tuning_logs\", exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# 2) TEMPLATE = YOUR my_algo.py CODE (UNCHANGED EXCEPT WE WILL\n",
        "#    regex-replace ONLY K_PER_FEATURE and TOP_FINAL)\n",
        "#    IMPORTANT: DETECTOR_NAME stays \"TDA_VEAD_Method\"\n",
        "# ============================================================\n",
        "TEMPLATE = r\"\"\"\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ripser import ripser\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "DETECTOR_NAME = \"TDA_VEAD_Method\"\n",
        "INPUT_DIR = \"data\"\n",
        "OUTPUT_DIR = os.path.join(\"results\", DETECTOR_NAME)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Embedding parameters (fixed in NAB for fairness)\n",
        "# ----------------------------------------------------------\n",
        "WINDOW_SIZE = 14\n",
        "TAU         = 1\n",
        "DIMENSION   = 7\n",
        "_EPS        = 1e-12\n",
        "MAXDIM      = 1  # H0 + H1\n",
        "\n",
        "# ==========================================================\n",
        "# 0. VEAD CONFIGURATION\n",
        "# ==========================================================\n",
        "KV   = 3.5\n",
        "KA   = 3.5\n",
        "MODE = \"abs_plateau\"  # \"strict\" | \"plateau\" | \"abs_plateau\"\n",
        "\n",
        "def _vead_series(raw_vals, kv=KV, ka=KA, mode=MODE):\n",
        "    s = pd.to_numeric(pd.Series(raw_vals, dtype=float), errors=\"coerce\") \\\n",
        "            .interpolate(limit_direction=\"both\")\n",
        "\n",
        "    v = s.diff(1)\n",
        "    a = v.diff(1)\n",
        "\n",
        "    def _zmad(x):\n",
        "        x = np.asarray(x, dtype=float)\n",
        "        med = np.nanmedian(x)\n",
        "        mad = np.nanmedian(np.abs(x - med)) + 1e-12\n",
        "        return (x - med) / mad\n",
        "\n",
        "    zv = _zmad(v.values)\n",
        "    za = _zmad(a.values)\n",
        "\n",
        "    mode = (mode or \"strict\").lower()\n",
        "    if mode == \"strict\":\n",
        "        zv = np.maximum(0.0, zv)\n",
        "        za = np.maximum(0.0, za)\n",
        "    elif mode == \"plateau\":\n",
        "        zv = np.where(zv > -0.25, zv, 0.0)\n",
        "        za = np.where(za > -0.25, za, 0.0)\n",
        "    elif mode == \"abs_plateau\":\n",
        "        zv = np.abs(zv)\n",
        "        za = np.abs(za)\n",
        "\n",
        "    score = (kv * zv) * (ka * za)\n",
        "    return np.nan_to_num(score, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "# ==========================================================\n",
        "# 1. TAKENS EMBEDDING\n",
        "# ==========================================================\n",
        "def takens_embed(window, time_delay, dimension):\n",
        "    m = len(window) - (dimension - 1) * time_delay\n",
        "    if m <= 0:\n",
        "        raise ValueError(\"Takens parameters too large for this window.\")\n",
        "    return np.stack(\n",
        "        [window[j:j + m * time_delay:time_delay] for j in range(dimension)],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "# ==========================================================\n",
        "# 2. PERSISTENCE DIAGRAM UTILITIES + FEATURE FUNCTIONS\n",
        "# ==========================================================\n",
        "def _clean_diag(diag):\n",
        "    if diag is None:\n",
        "        return np.empty((0, 2), dtype=float)\n",
        "    arr = np.asarray(diag, dtype=float)\n",
        "    if arr.ndim != 2 or arr.shape[1] != 2 or arr.size == 0:\n",
        "        return np.empty((0, 2), dtype=float)\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    mask = np.isfinite(b) & np.isfinite(d) & (d > b)\n",
        "    if not np.any(mask):\n",
        "        return np.empty((0, 2), dtype=float)\n",
        "    return np.stack([b[mask], d[mask]], axis=1)\n",
        "\n",
        "def _lifetimes(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return np.empty(0, dtype=float)\n",
        "    return np.maximum(arr[:, 1] - arr[:, 0], 0.0)\n",
        "\n",
        "def _safe_div(a, b):\n",
        "    return float(a) / float(b + _EPS)\n",
        "\n",
        "try:\n",
        "    _trapz = np.trapezoid\n",
        "except AttributeError:\n",
        "    _trapz = np.trapz\n",
        "\n",
        "def _auc_tri_max(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return 0.0\n",
        "    b_all, d_all = arr[:, 0], arr[:, 1]\n",
        "    if b_all.min() == d_all.max():\n",
        "        return 0.0\n",
        "\n",
        "    grid = np.linspace(b_all.min(), d_all.max(), 64)\n",
        "    lam1 = np.zeros_like(grid)\n",
        "\n",
        "    for b, d in arr:\n",
        "        m = 0.5 * (b + d)\n",
        "        h = 0.5 * (d - b)\n",
        "        if h <= 0:\n",
        "            continue\n",
        "\n",
        "        left = (grid >= b) & (grid <= m)\n",
        "        right = (grid >= m) & (grid <= d)\n",
        "\n",
        "        lam1[left] = np.maximum(lam1[left], (grid[left] - b) * (h / max(m - b, _EPS)))\n",
        "        lam1[right] = np.maximum(lam1[right], (d - grid[right]) * (h / max(d - m, _EPS)))\n",
        "\n",
        "    return float(_trapz(lam1, grid))\n",
        "\n",
        "def _persistence_entropy(diag):\n",
        "    L = _lifetimes(diag)\n",
        "    if L.size == 0:\n",
        "        return 0.0\n",
        "    S = L.sum()\n",
        "    if S <= 0:\n",
        "        return 0.0\n",
        "    p = L / (S + _EPS)\n",
        "    return float(-np.sum(p * np.log(p + _EPS)))\n",
        "\n",
        "def _gini_from_lifetimes(L):\n",
        "    L = np.sort(L)\n",
        "    n = len(L)\n",
        "    if n == 0:\n",
        "        return 0.0\n",
        "    S = L.sum()\n",
        "    if S <= 0:\n",
        "        return 0.0\n",
        "    cumL = np.cumsum(L)\n",
        "    return float(1 + 1/n - 2*np.sum(cumL/(n*S)))\n",
        "\n",
        "def _tail_share_q(diag, q):\n",
        "    L = _lifetimes(diag)\n",
        "    if L.size == 0:\n",
        "        return 0.0\n",
        "    qv = np.quantile(L, q)\n",
        "    return _safe_div(L[L >= qv].sum(), L.sum())\n",
        "\n",
        "def _birth_death_stats(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return {\"mean_birth\": 0.0, \"mean_death\": 0.0, \"std_birth\": 0.0, \"std_death\": 0.0}\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    return {\n",
        "        \"mean_birth\": float(b.mean()),\n",
        "        \"mean_death\": float(d.mean()),\n",
        "        \"std_birth\": float(b.std(ddof=0)),\n",
        "        \"std_death\": float(d.std(ddof=0)),\n",
        "    }\n",
        "\n",
        "def _diag_distance_stats(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return {\"mean_diag_dist\": 0.0, \"max_diag_dist\": 0.0, \"sum_diag_dist\": 0.0}\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    dist = (d - b) / np.sqrt(2.0)\n",
        "    return {\n",
        "        \"mean_diag_dist\": float(dist.mean()),\n",
        "        \"max_diag_dist\": float(dist.max()),\n",
        "        \"sum_diag_dist\": float(dist.sum()),\n",
        "    }\n",
        "\n",
        "def _centroid_xy(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return {\"centroid_x\": 0.0, \"centroid_y\": 0.0}\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    L = np.maximum(d - b, 0.0)\n",
        "    S = L.sum()\n",
        "    if S <= 0:\n",
        "        return {\"centroid_x\": 0.0, \"centroid_y\": 0.0}\n",
        "    return {\n",
        "        \"centroid_x\": float(np.sum(b * L) / (S + _EPS)),\n",
        "        \"centroid_y\": float(np.sum(d * L) / (S + _EPS)),\n",
        "    }\n",
        "\n",
        "def _lifetimes_stats(diag):\n",
        "    L = _lifetimes(diag)\n",
        "    if L.size == 0:\n",
        "        return {\n",
        "            \"count\": 0, \"sum\": 0.0, \"mean\": 0.0, \"median\": 0.0, \"std\": 0.0,\n",
        "            \"min\": 0.0, \"max\": 0.0, \"L1\": 0.0, \"L2\": 0.0, \"Linf\": 0.0\n",
        "        }\n",
        "    return {\n",
        "        \"count\": int(L.size),\n",
        "        \"sum\": float(L.sum()),\n",
        "        \"mean\": float(L.mean()),\n",
        "        \"median\": float(np.median(L)),\n",
        "        \"std\": float(L.std(ddof=0)),\n",
        "        \"min\": float(L.min()),\n",
        "        \"max\": float(L.max()),\n",
        "        \"L1\": float(np.sum(np.abs(L))),\n",
        "        \"L2\": float(np.sqrt(np.sum(L**2))),\n",
        "        \"Linf\": float(np.max(np.abs(L))),\n",
        "    }\n",
        "\n",
        "def _lifetimes_quantiles(diag):\n",
        "    L = _lifetimes(diag)\n",
        "    if L.size == 0:\n",
        "        return {\"q50\": 0.0, \"q75\": 0.0, \"q90\": 0.0, \"q95\": 0.0, \"q99\": 0.0}\n",
        "    return {\n",
        "        \"q50\": float(np.quantile(L, 0.50)),\n",
        "        \"q75\": float(np.quantile(L, 0.75)),\n",
        "        \"q90\": float(np.quantile(L, 0.90)),\n",
        "        \"q95\": float(np.quantile(L, 0.95)),\n",
        "        \"q99\": float(np.quantile(L, 0.99)),\n",
        "    }\n",
        "\n",
        "def _carlsson_coordinates(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return {f\"f{k}\": 0.0 for k in range(1, 6)}\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    L = np.maximum(d - b, 0.0)\n",
        "    S = L.sum()\n",
        "    if S <= 0:\n",
        "        return {f\"f{k}\": 0.0 for k in range(1, 6)}\n",
        "    return {\n",
        "        \"f1\": float(L.sum()),\n",
        "        \"f2\": float(np.sum(b * L)),\n",
        "        \"f3\": float(np.sum(d * L)),\n",
        "        \"f4\": float(np.sum(b**2 * L)),\n",
        "        \"f5\": float(np.sum(d**2 * L)),\n",
        "    }\n",
        "\n",
        "def _sum_centroid_radial(diag):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return 0.0\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    L = np.maximum(d - b, 0.0)\n",
        "    S = L.sum()\n",
        "    if S <= 0:\n",
        "        return 0.0\n",
        "    radial = (b + d) / np.sqrt(2.0)\n",
        "    return _safe_div(np.sum(np.abs(radial) * L), S)\n",
        "\n",
        "def _pete(diag, p=1.6, q=0.5):\n",
        "    arr = _clean_diag(diag)\n",
        "    if arr.size == 0:\n",
        "        return 0.0\n",
        "    b, d = arr[:, 0], arr[:, 1]\n",
        "    L = np.maximum(d - b, 0.0)\n",
        "    S = L.sum()\n",
        "    if S <= 0:\n",
        "        return 0.0\n",
        "    radial = (b + d) / np.sqrt(2.0)\n",
        "    return _safe_div(np.sum((L**p) * (np.abs(radial)**q)), S)\n",
        "\n",
        "def compute_features_for_diag(diag, prefix):\n",
        "    feats = {}\n",
        "\n",
        "    Ls = _lifetimes_stats(diag)\n",
        "    feats[f\"{prefix}count_lifetime\"] = float(Ls[\"count\"])\n",
        "    feats[f\"{prefix}sum_lifetime\"]   = float(Ls[\"sum\"])\n",
        "    feats[f\"{prefix}mean_lifetime\"]  = float(Ls[\"mean\"])\n",
        "    feats[f\"{prefix}median_lifetime\"]= float(Ls[\"median\"])\n",
        "    feats[f\"{prefix}std_lifetime\"]   = float(Ls[\"std\"])\n",
        "    feats[f\"{prefix}min_lifetime\"]   = float(Ls[\"min\"])\n",
        "    feats[f\"{prefix}max_lifetime\"]   = float(Ls[\"max\"])\n",
        "\n",
        "    feats[f\"{prefix}L1_lifetime\"]    = float(Ls[\"L1\"])\n",
        "    feats[f\"{prefix}L2_lifetime\"]    = float(Ls[\"L2\"])\n",
        "    feats[f\"{prefix}Linf_lifetime\"]  = float(Ls[\"Linf\"])\n",
        "\n",
        "    feats[f\"{prefix}L1_norm\"]        = float(Ls[\"L1\"])\n",
        "    feats[f\"{prefix}L2_norm\"]        = float(Ls[\"L2\"])\n",
        "    feats[f\"{prefix}Linf_norm\"]      = float(Ls[\"Linf\"])\n",
        "\n",
        "    feats[f\"{prefix}betti\"]          = float(Ls[\"count\"])\n",
        "    feats[f\"{prefix}energy_concentration\"] = _safe_div(Ls[\"L2\"], Ls[\"L1\"])\n",
        "    feats[f\"{prefix}dominance_share\"]      = _safe_div(Ls[\"Linf\"], Ls[\"L1\"])\n",
        "\n",
        "    feats[f\"{prefix}persistence_entropy\"]  = _persistence_entropy(diag)\n",
        "\n",
        "    bd = _birth_death_stats(diag)\n",
        "    for k, v in bd.items():\n",
        "        feats[f\"{prefix}{k}\"] = float(v)\n",
        "\n",
        "    dd = _diag_distance_stats(diag)\n",
        "    for k, v in dd.items():\n",
        "        feats[f\"{prefix}{k}\"] = float(v)\n",
        "\n",
        "    cxy = _centroid_xy(diag)\n",
        "    feats[f\"{prefix}centroid_x\"] = float(cxy[\"centroid_x\"])\n",
        "    feats[f\"{prefix}centroid_y\"] = float(cxy[\"centroid_y\"])\n",
        "\n",
        "    q = _lifetimes_quantiles(diag)\n",
        "    for k, v in q.items():\n",
        "        feats[f\"{prefix}{k}\"] = float(v)\n",
        "\n",
        "    tail80 = _tail_share_q(diag, 0.80)\n",
        "    tail90 = _tail_share_q(diag, 0.90)\n",
        "    tail95 = _tail_share_q(diag, 0.95)\n",
        "\n",
        "    feats[f\"{prefix}tail_share_q80\"] = float(tail80)\n",
        "    feats[f\"{prefix}tail_share_q90\"] = float(tail90)\n",
        "    feats[f\"{prefix}tail_share_q95\"] = float(tail95)\n",
        "    feats[f\"{prefix}tail_curvature_80_90\"] = float(tail90 - tail80)\n",
        "\n",
        "    L = _lifetimes(diag)\n",
        "    feats[f\"{prefix}gini\"] = float(_gini_from_lifetimes(L))\n",
        "\n",
        "    cc = _carlsson_coordinates(diag)\n",
        "    feats[f\"{prefix}Carlsson_f1\"] = float(cc[\"f1\"])\n",
        "    feats[f\"{prefix}Carlsson_f2\"] = float(cc[\"f2\"])\n",
        "    feats[f\"{prefix}Carlsson_f3\"] = float(cc[\"f3\"])\n",
        "    feats[f\"{prefix}Carlsson_f4\"] = float(cc[\"f4\"])\n",
        "    feats[f\"{prefix}Carlsson_f5\"] = float(cc[\"f5\"])\n",
        "\n",
        "    if prefix == \"H0_\":\n",
        "        A = _auc_tri_max(diag)\n",
        "        feats[\"H0_ratio_auc_L1_to_sum\"] = _safe_div(A, Ls[\"sum\"])\n",
        "        feats[\"H0_ratio_auc_to_max\"]    = _safe_div(A, Ls[\"max\"])\n",
        "        feats[\"H0_ratio_auc_to_l2\"]     = _safe_div(A, Ls[\"L2\"])\n",
        "        feats[\"H0_bottleneck\"]          = float(Ls[\"max\"])\n",
        "        feats[\"H0_sum_centroid\"]        = float(_sum_centroid_radial(diag))\n",
        "        feats[\"PETE_p1.6_q0.5\"]         = float(_pete(diag, p=1.6, q=0.5))\n",
        "        feats[\"H0_energy_concentration\"]= _safe_div(Ls[\"L2\"], Ls[\"sum\"])\n",
        "        feats[\"H0_dominance_share\"]     = _safe_div(Ls[\"Linf\"], Ls[\"sum\"])\n",
        "        feats[\"H0_tail_curvature_80_90\"]= float(tail90 - tail80)\n",
        "        feats[\"H0_centroid_to_energy\"]  = _safe_div(feats[\"H0_sum_centroid\"], Ls[\"L2\"])\n",
        "        feats[\"H0_gini\"]                = float(feats[\"H0_gini\"])\n",
        "    return feats\n",
        "\n",
        "def compute_cross_dim_features(feats_H0, feats_H1):\n",
        "    out = {}\n",
        "    def g(d, k): return float(d.get(k, 0.0))\n",
        "    out[\"H1_to_H0_betti_ratio\"]   = _safe_div(g(feats_H1, \"H1_betti\"), g(feats_H0, \"H0_betti\"))\n",
        "    out[\"H1_to_H0_entropy_ratio\"] = _safe_div(g(feats_H1, \"H1_persistence_entropy\"), g(feats_H0, \"H0_persistence_entropy\"))\n",
        "    return out\n",
        "\n",
        "FEATURE_NAMES = [\n",
        "    \"H0_Carlsson_f1\",\"H0_Carlsson_f3\",\"H0_Carlsson_f5\",\n",
        "    \"H0_L1_lifetime\",\"H0_L1_norm\",\"H0_L2_lifetime\",\"H0_L2_norm\",\n",
        "    \"H0_Linf_lifetime\",\"H0_Linf_norm\",\"H0_bottleneck\",\"H0_centroid_to_energy\",\n",
        "    \"H0_centroid_y\",\"H0_dominance_share\",\"H0_energy_concentration\",\"H0_gini\",\n",
        "    \"H0_max_diag_dist\",\"H0_max_lifetime\",\"H0_mean_death\",\"H0_mean_diag_dist\",\n",
        "    \"H0_mean_lifetime\",\"H0_median_lifetime\",\"H0_min_lifetime\",\"H0_persistence_entropy\",\n",
        "    \"H0_q50\",\"H0_q75\",\"H0_q90\",\"H0_q95\",\"H0_q99\",\"H0_ratio_auc_L1_to_sum\",\n",
        "    \"H0_ratio_auc_to_l2\",\"H0_ratio_auc_to_max\",\"H0_std_death\",\"H0_std_lifetime\",\n",
        "    \"H0_sum_centroid\",\"H0_sum_diag_dist\",\"H0_sum_lifetime\",\"H0_tail_curvature_80_90\",\n",
        "    \"H0_tail_share_q80\",\"H0_tail_share_q90\",\"H0_tail_share_q95\",\n",
        "    \"H1_Carlsson_f1\",\"H1_Carlsson_f2\",\"H1_Carlsson_f3\",\n",
        "    \"H1_L1_lifetime\",\"H1_L1_norm\",\"H1_L2_lifetime\",\"H1_L2_norm\",\n",
        "    \"H1_Linf_lifetime\",\"H1_Linf_norm\",\"H1_betti\",\"H1_count_lifetime\",\n",
        "    \"H1_dominance_share\",\"H1_energy_concentration\",\"H1_gini\",\n",
        "    \"H1_max_diag_dist\",\"H1_max_lifetime\",\"H1_mean_diag_dist\",\"H1_mean_lifetime\",\n",
        "    \"H1_median_lifetime\",\"H1_min_lifetime\",\"H1_persistence_entropy\",\n",
        "    \"H1_q50\",\"H1_q75\",\"H1_q90\",\"H1_q95\",\"H1_q99\",\n",
        "    \"H1_std_birth\",\"H1_std_death\",\"H1_std_lifetime\",\n",
        "    \"H1_sum_diag_dist\",\"H1_sum_lifetime\",\n",
        "    \"H1_tail_share_q80\",\"H1_tail_share_q90\",\"H1_tail_share_q95\",\n",
        "    \"H1_to_H0_betti_ratio\",\"H1_to_H0_entropy_ratio\",\n",
        "    \"PETE_p1.6_q0.5\"\n",
        "]\n",
        "\n",
        "def run():\n",
        "    files = glob.glob(os.path.join(INPUT_DIR, \"**\", \"*.csv\"), recursive=True)\n",
        "    print(f\"Found {len(files)} data files in '{INPUT_DIR}'\")\n",
        "\n",
        "    ##############################################################################################################\n",
        "    # Voting config\n",
        "    K_PER_FEATURE = 4  # each feature votes for top-2 indices\n",
        "    TOP_FINAL     = 10  # final anomalies = top-5 voted indices\n",
        "    ########################################################################################################################333\n",
        "\n",
        "    for filepath in files:\n",
        "        if \".ipynb_checkpoints\" in filepath:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(filepath)\n",
        "            df.columns = [c.strip().lower() for c in df.columns]\n",
        "            if \"value\" not in df.columns or \"timestamp\" not in df.columns:\n",
        "                continue\n",
        "\n",
        "            vals = pd.to_numeric(df[\"value\"], errors=\"coerce\").astype(float).to_numpy()\n",
        "            n = len(vals)\n",
        "\n",
        "            rows = []\n",
        "            for i in range(WINDOW_SIZE - 1, n):\n",
        "                w = vals[i - WINDOW_SIZE + 1 : i + 1]\n",
        "                try:\n",
        "                    emb = takens_embed(w, TAU, DIMENSION)\n",
        "                    dgms = ripser(emb, maxdim=MAXDIM)[\"dgms\"]\n",
        "                except Exception:\n",
        "                    dgms = [np.empty((0, 2)), np.empty((0, 2))]\n",
        "\n",
        "                D0 = dgms[0] if len(dgms) > 0 else np.empty((0, 2))\n",
        "                D1 = dgms[1] if (MAXDIM >= 1 and len(dgms) > 1) else np.empty((0, 2))\n",
        "\n",
        "                feats_H0 = compute_features_for_diag(D0, \"H0_\")\n",
        "                feats_H1 = compute_features_for_diag(D1, \"H1_\")\n",
        "                cross    = compute_cross_dim_features(feats_H0, feats_H1)\n",
        "\n",
        "                merged = {}\n",
        "                merged.update(feats_H0)\n",
        "                merged.update(feats_H1)\n",
        "                merged.update(cross)\n",
        "                merged[\"index\"] = i\n",
        "                rows.append(merged)\n",
        "\n",
        "            feat_df = pd.DataFrame(rows)\n",
        "            full = pd.DataFrame(index=np.arange(n))\n",
        "            if not feat_df.empty:\n",
        "                feat_df = feat_df.set_index(\"index\")\n",
        "                full = full.join(feat_df, how=\"left\")\n",
        "\n",
        "            full = full.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "\n",
        "            votes = np.zeros(n, dtype=int)\n",
        "\n",
        "            for feat_name in FEATURE_NAMES:\n",
        "                series = pd.to_numeric(full.get(feat_name, 0.0), errors=\"coerce\").astype(float).to_numpy()\n",
        "                series = np.nan_to_num(series, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "                vead_scores = _vead_series(series, kv=KV, ka=KA, mode=MODE)\n",
        "\n",
        "                mx = float(np.max(vead_scores)) if len(vead_scores) else 0.0\n",
        "                if (not np.isfinite(mx)) or mx <= 0:\n",
        "                    continue\n",
        "\n",
        "                scores01 = np.clip(vead_scores / mx, 0.0, 1.0)\n",
        "                if np.max(scores01) <= 0:\n",
        "                    continue\n",
        "\n",
        "                k_eff = min(K_PER_FEATURE, n)\n",
        "                topk_idx = np.argpartition(scores01, -k_eff)[-k_eff:]\n",
        "                topk_idx = topk_idx[np.lexsort((topk_idx, -scores01[topk_idx]))]\n",
        "                votes[topk_idx] += 1\n",
        "\n",
        "            final_scores = np.zeros(n, dtype=float)\n",
        "            if np.max(votes) > 0:\n",
        "                top_final_eff = min(TOP_FINAL, n)\n",
        "                order = np.lexsort((np.arange(n), -votes))\n",
        "                chosen = order[:top_final_eff]\n",
        "                final_scores[chosen] = 1.0\n",
        "\n",
        "            rel = os.path.relpath(filepath, INPUT_DIR)\n",
        "            category = os.path.dirname(rel)\n",
        "            base_name = os.path.basename(rel)\n",
        "\n",
        "            out_dir = os.path.join(OUTPUT_DIR, category)\n",
        "            os.makedirs(out_dir, exist_ok=True)\n",
        "            out_name = f\"{DETECTOR_NAME}_\" + base_name\n",
        "            out_path = os.path.join(out_dir, out_name)\n",
        "\n",
        "            out_df = pd.DataFrame({\n",
        "                \"timestamp\": df[\"timestamp\"],\n",
        "                \"anomaly_score\": final_scores\n",
        "            })\n",
        "            out_df.to_csv(out_path, index=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"!! Error processing {filepath}: {e}\")\n",
        "            continue\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run()\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================\n",
        "# 3) Helpers\n",
        "# ============================================================\n",
        "def run_cmd(cmd_list):\n",
        "    p = subprocess.run(cmd_list, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    return p.returncode, p.stdout\n",
        "\n",
        "def parse_final_scores(text):\n",
        "    # works for ANY profile names printed by NAB\n",
        "    pat = r\"Final score for '([^']+)' detector on '([^']+)' profile = ([\\-0-9.]+)\"\n",
        "    found = re.findall(pat, text)\n",
        "    # returns dict: {(detectorLabel, profileName): score}\n",
        "    return {(d, prof): float(val) for d, prof, val in found}\n",
        "\n",
        "def make_variant_code(template, K, TOP):\n",
        "    code = template\n",
        "    code = re.sub(r'K_PER_FEATURE\\s*=\\s*\\d+', f'K_PER_FEATURE = {K}', code, count=1)\n",
        "    code = re.sub(r'TOP_FINAL\\s*=\\s*\\d+',     f'TOP_FINAL = {TOP}', code, count=1)\n",
        "    return code\n",
        "\n",
        "# ============================================================\n",
        "# 4) GRID SEARCH\n",
        "# ============================================================\n",
        "K_LIST   = [6,7,8,9,10]\n",
        "TOP_LIST = [11,13,15,17,19]\n",
        "\n",
        "results = []\n",
        "\n",
        "for K, TOP in itertools.product(K_LIST, TOP_LIST):\n",
        "    exp_id = f\"K{K}_TOP{TOP}\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"EXPERIMENT: K_PER_FEATURE={K}, TOP_FINAL={TOP}  ->  TDA_VEAD_Method\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Write detector code (only K/TOP changed)\n",
        "    code = make_variant_code(TEMPLATE, K, TOP)\n",
        "    with open(\"my_algo.py\", \"w\") as f:\n",
        "        f.write(code)\n",
        "\n",
        "    # Run detector (generates results/TDA_VEAD_Method/*)\n",
        "    rc1, out1 = run_cmd([\"python\", \"my_algo.py\"])\n",
        "    if rc1 != 0:\n",
        "        print(\"Detector failed.\")\n",
        "        results.append({\n",
        "            \"K_PER_FEATURE\": K, \"TOP_FINAL\": TOP,\n",
        "            \"standard\": None, \"lowFP\": None, \"lowFN\": None,\n",
        "            \"status\": \"detector_failed\"\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # Run NAB scoring (IMPORTANT: --skipConfirmation)\n",
        "    rc2, out2 = run_cmd([\n",
        "        \"python\", \"run.py\",\n",
        "        \"--optimize\", \"--score\",\n",
        "        \"--detectors\", \"TDA_VEAD_Method\",\n",
        "        \"--normalize\",\n",
        "        \"--skipConfirmation\"\n",
        "    ])\n",
        "\n",
        "    # Save full log for this experiment (super useful)\n",
        "    log_path = f\"/content/NAB/tuning_logs/runpy_{exp_id}.log\"\n",
        "    with open(log_path, \"w\") as f:\n",
        "        f.write(out2)\n",
        "\n",
        "    scores = parse_final_scores(out2)\n",
        "\n",
        "    # Try to pick the usual 3 profiles if they exist; otherwise leave None\n",
        "    # Note: detector label in NAB output is often 'TDA' even if detector module is custom.\n",
        "    # So we search across any detector label.\n",
        "    def pick(profile_name):\n",
        "        for (det_label, prof), val in scores.items():\n",
        "            if prof == profile_name:\n",
        "                return val\n",
        "        return None\n",
        "\n",
        "    row = {\n",
        "        \"K_PER_FEATURE\": K,\n",
        "        \"TOP_FINAL\": TOP,\n",
        "        \"standard\": pick(\"standard\") or pick(\"VEAD_Method_standard\"),\n",
        "        \"lowFP\":    pick(\"reward_low_FP_rate\") or pick(\"VEAD_Method_reward_low_FP_rate\"),\n",
        "        \"lowFN\":    pick(\"reward_low_FN_rate\") or pick(\"VEAD_Method_reward_low_FN_rate\"),\n",
        "        \"rc_score\": rc2,\n",
        "        \"log_file\": log_path,\n",
        "        \"status\": \"ok\" if (rc2 == 0 and len(scores) > 0) else \"score_parse_failed\"\n",
        "    }\n",
        "    results.append(row)\n",
        "    print(\"Extracted:\", row)\n",
        "\n",
        "# ============================================================\n",
        "# 5) SAVE RESULTS\n",
        "# ============================================================\n",
        "res_df = pd.DataFrame(results)\n",
        "out_csv = \"/content/NAB/parameter_tuning_results.csv\"\n",
        "res_df.to_csv(out_csv, index=False)\n",
        "print(\"\\n✅ Saved:\", out_csv)\n",
        "\n",
        "best = res_df.dropna(subset=[\"standard\"]).sort_values(\"standard\", ascending=False).head(10)\n",
        "print(\"\\nTop 10 by standard score:\")\n",
        "print(best[[\"K_PER_FEATURE\",\"TOP_FINAL\",\"standard\",\"lowFP\",\"lowFN\",\"status\",\"log_file\"]])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNXU4xHA8j/EHv3hAIm0T6c",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}